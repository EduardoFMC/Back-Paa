{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReferÃªncia: https://github.com/prashil2792/Question-Answering-System-Deep-Learning/blob/master/Question%20Answering%20Memory%20Network.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from classes import Preprocessing, Model, Lstm, Similarity, Bert, SentenceTransformers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "\n",
    "SEED_VAL = 42\n",
    "random.seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "tf.random.set_seed(SEED_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Bulbasaur its a Grass first generation Pokemon...</td>\n",
       "      <td>Whats the type of Bulbasaur?</td>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Ivysaur its a Grass first generation Pokemon t...</td>\n",
       "      <td>Whats the type of Ivysaur?</td>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Venusaur its a Grass first generation Pokemon ...</td>\n",
       "      <td>Whats the type of Venusaur?</td>\n",
       "      <td>Grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Charmander its a Fire first generation Pokemon...</td>\n",
       "      <td>Whats the type of Charmander?</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Charmeleon its a Fire first generation Pokemon...</td>\n",
       "      <td>Whats the type of Charmeleon?</td>\n",
       "      <td>Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       title                                            context  \\\n",
       "0   2   Bulbasaur  Bulbasaur its a Grass first generation Pokemon...   \n",
       "1   3     Ivysaur  Ivysaur its a Grass first generation Pokemon t...   \n",
       "2   4    Venusaur  Venusaur its a Grass first generation Pokemon ...   \n",
       "3   5  Charmander  Charmander its a Fire first generation Pokemon...   \n",
       "4   6  Charmeleon  Charmeleon its a Fire first generation Pokemon...   \n",
       "\n",
       "                        question answers  \n",
       "0   Whats the type of Bulbasaur?   Grass  \n",
       "1     Whats the type of Ivysaur?   Grass  \n",
       "2    Whats the type of Venusaur?   Grass  \n",
       "3  Whats the type of Charmander?    Fire  \n",
       "4  Whats the type of Charmeleon?    Fire  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/pokemon_contexts2.csv\", sep=',')  \n",
    "\n",
    "df['answers'] = df['answers']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Bulbasaur its a Grass first generation Pokemon...</td>\n",
       "      <td>[whats, the, type, of, bulbasaur, ?]</td>\n",
       "      <td>[grass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Ivysaur its a Grass first generation Pokemon t...</td>\n",
       "      <td>[whats, the, type, of, ivysaur, ?]</td>\n",
       "      <td>[grass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Venusaur its a Grass first generation Pokemon ...</td>\n",
       "      <td>[whats, the, type, of, venusaur, ?]</td>\n",
       "      <td>[grass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Charmander its a Fire first generation Pokemon...</td>\n",
       "      <td>[whats, the, type, of, charmander, ?]</td>\n",
       "      <td>[fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Charmeleon its a Fire first generation Pokemon...</td>\n",
       "      <td>[whats, the, type, of, charmeleon, ?]</td>\n",
       "      <td>[fire]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       title                                            context  \\\n",
       "0   2   Bulbasaur  Bulbasaur its a Grass first generation Pokemon...   \n",
       "1   3     Ivysaur  Ivysaur its a Grass first generation Pokemon t...   \n",
       "2   4    Venusaur  Venusaur its a Grass first generation Pokemon ...   \n",
       "3   5  Charmander  Charmander its a Fire first generation Pokemon...   \n",
       "4   6  Charmeleon  Charmeleon its a Fire first generation Pokemon...   \n",
       "\n",
       "                                question  answers  \n",
       "0   [whats, the, type, of, bulbasaur, ?]  [grass]  \n",
       "1     [whats, the, type, of, ivysaur, ?]  [grass]  \n",
       "2    [whats, the, type, of, venusaur, ?]  [grass]  \n",
       "3  [whats, the, type, of, charmander, ?]   [fire]  \n",
       "4  [whats, the, type, of, charmeleon, ?]   [fire]  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = Preprocessing()\n",
    "\n",
    "pp_df, corpus_pp_desc_q, corpus_pp_desc_a = Preprocessing.apply_preprocessing(df)\n",
    "\n",
    "pp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 70%\n",
      "val: 10%\n",
      "test: 21%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[whats, the, type, of, poliwag, ?]</td>\n",
       "      <td>[water]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[whats, the, type, of, seadra, ?]</td>\n",
       "      <td>[water]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[whats, the, type, of, pidgey, ?]</td>\n",
       "      <td>[normal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[whats, the, type, of, poliwrath, ?]</td>\n",
       "      <td>[water]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[whats, the, type, of, ivysaur, ?]</td>\n",
       "      <td>[grass]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question   answers\n",
       "59     [whats, the, type, of, poliwag, ?]   [water]\n",
       "116     [whats, the, type, of, seadra, ?]   [water]\n",
       "15      [whats, the, type, of, pidgey, ?]  [normal]\n",
       "61   [whats, the, type, of, poliwrath, ?]   [water]\n",
       "1      [whats, the, type, of, ivysaur, ?]   [grass]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val, df_test = preprocessing.split_dataset(df=pp_df, columns=['question'], label='answers', seed=SEED_VAL)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Mean sequence length: 6.0\n",
      "Max sequence length: 6\n",
      "Answer:\n",
      "Mean sequence length: 1.0\n",
      "Max sequence length: 1\n"
     ]
    }
   ],
   "source": [
    "mean_sequence_length_q, max_sequence_length_q = Preprocessing.get_sequences_details(df_train['question'])\n",
    "mean_sequence_length_a, max_sequence_length_a = Preprocessing.get_sequences_details(df_train['answers'])\n",
    "\n",
    "print(\"Question:\")\n",
    "print(f'Mean sequence length: {mean_sequence_length_q}')\n",
    "print(f'Max sequence length: {max_sequence_length_q}')\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(f'Mean sequence length: {mean_sequence_length_a}')\n",
    "print(f'Max sequence length: {max_sequence_length_a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Training features shape: (105, 6)\n",
      "Validation features shape: (15, 6)\n",
      "Test features shape: (31, 6)\n",
      "Answer:\n",
      "Training features shape: (105, 6)\n",
      "Validation features shape: (15, 6)\n",
      "Test features shape: (31, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5,  6,  1,  1],\n",
       "       [ 3,  4,  5,  7,  1,  1],\n",
       "       [ 3,  4,  5,  8,  1,  1],\n",
       "       [ 3,  4,  5,  9,  1,  1],\n",
       "       [ 3,  4,  5, 10,  1,  1],\n",
       "       [ 3,  4,  5, 11,  1,  1],\n",
       "       [ 3,  4,  5, 12,  1,  1],\n",
       "       [ 3,  4,  5, 13,  1,  1],\n",
       "       [ 3,  4,  5, 14,  1,  1],\n",
       "       [ 3,  4,  5, 15,  1,  1]], dtype=int32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = max_sequence_length_q if max_sequence_length_q > max_sequence_length_a else max_sequence_length_a\n",
    "\n",
    "vocab_size_q, X_train_padded, X_val_padded, X_test_padded = Preprocessing.adapt_X_for_input_layer(df_train['question'].astype(str), df_val['question'].astype(str), df_test['question'].astype(str), MAX_SEQUENCE_LENGTH)\n",
    "vocab_size_a, Y_train_padded, Y_val_padded, Y_test_padded = Preprocessing.adapt_X_for_input_layer(df_train['answers'].astype(str), df_val['answers'].astype(str), df_test['answers'].astype(str), MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"Question:\")\n",
    "print('Training features shape:', X_train_padded.shape)\n",
    "print('Validation features shape:', X_val_padded.shape)\n",
    "print('Test features shape:', X_test_padded.shape)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print('Training features shape:', Y_train_padded.shape)\n",
    "print('Validation features shape:', Y_val_padded.shape)\n",
    "print('Test features shape:', Y_test_padded.shape)\n",
    "\n",
    "X_train_padded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answers\n",
       "[water]       23\n",
       "[normal]      11\n",
       "[fire]        10\n",
       "[grass]        9\n",
       "[bug]          9\n",
       "[poison]       9\n",
       "[rock]         7\n",
       "[psychic]      7\n",
       "[electric]     5\n",
       "[ground]       4\n",
       "[fighting]     4\n",
       "[ghost]        3\n",
       "[fairy]        2\n",
       "[ice]          1\n",
       "[dragon]       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['answers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = vocab_size_q if vocab_size_q > vocab_size_a else vocab_size_a\n",
    "METRICS = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"'d\",\n",
       " '?',\n",
       " 'abra',\n",
       " 'aerodactyl',\n",
       " 'alakazam',\n",
       " 'arbok',\n",
       " 'arcanine',\n",
       " 'articuno',\n",
       " 'beedrill',\n",
       " 'bellsprout',\n",
       " 'blastoise',\n",
       " 'bug',\n",
       " 'bulbasaur',\n",
       " 'butterfree',\n",
       " 'caterpie',\n",
       " 'chansey',\n",
       " 'charizard',\n",
       " 'charmander',\n",
       " 'charmeleon',\n",
       " 'clefable',\n",
       " 'clefairy',\n",
       " 'cloyster',\n",
       " 'cubone',\n",
       " 'dewgong',\n",
       " 'diglett',\n",
       " 'ditto',\n",
       " 'dodrio',\n",
       " 'doduo',\n",
       " 'dragon',\n",
       " 'dragonair',\n",
       " 'dragonite',\n",
       " 'dratini',\n",
       " 'drowzee',\n",
       " 'dugtrio',\n",
       " 'eevee',\n",
       " 'ekans',\n",
       " 'electabuzz',\n",
       " 'electric',\n",
       " 'electrode',\n",
       " 'exeggcute',\n",
       " 'exeggutor',\n",
       " 'fairy',\n",
       " 'farfetch',\n",
       " 'fearow',\n",
       " 'fighting',\n",
       " 'fire',\n",
       " 'flareon',\n",
       " 'gastly',\n",
       " 'gengar',\n",
       " 'geodude',\n",
       " 'ghost',\n",
       " 'gloom',\n",
       " 'golbat',\n",
       " 'goldeen',\n",
       " 'golduck',\n",
       " 'golem',\n",
       " 'grass',\n",
       " 'graveler',\n",
       " 'grimer',\n",
       " 'ground',\n",
       " 'growlithe',\n",
       " 'gyarados',\n",
       " 'haunter',\n",
       " 'hitmonchan',\n",
       " 'hitmonlee',\n",
       " 'horsea',\n",
       " 'hypno',\n",
       " 'ice',\n",
       " 'ivysaur',\n",
       " 'jigglypuff',\n",
       " 'jolteon',\n",
       " 'jynx',\n",
       " 'kabuto',\n",
       " 'kabutops',\n",
       " 'kadabra',\n",
       " 'kakuna',\n",
       " 'kangaskhan',\n",
       " 'kingler',\n",
       " 'koffing',\n",
       " 'krabby',\n",
       " 'lapras',\n",
       " 'lickitung',\n",
       " 'machamp',\n",
       " 'machoke',\n",
       " 'machop',\n",
       " 'magikarp',\n",
       " 'magmar',\n",
       " 'magnemite',\n",
       " 'magneton',\n",
       " 'mankey',\n",
       " 'marowak',\n",
       " 'meowth',\n",
       " 'metapod',\n",
       " 'mew',\n",
       " 'mewtwo',\n",
       " 'moltres',\n",
       " 'mr._mime',\n",
       " 'muk',\n",
       " 'nidoking',\n",
       " 'nidoqueen',\n",
       " 'nidoranâ',\n",
       " 'nidoranâ',\n",
       " 'nidorina',\n",
       " 'nidorino',\n",
       " 'ninetales',\n",
       " 'normal',\n",
       " 'oddish',\n",
       " 'of',\n",
       " 'omanyte',\n",
       " 'omastar',\n",
       " 'onix',\n",
       " 'paras',\n",
       " 'parasect',\n",
       " 'persian',\n",
       " 'pidgeot',\n",
       " 'pidgeotto',\n",
       " 'pidgey',\n",
       " 'pikachu',\n",
       " 'pinsir',\n",
       " 'poison',\n",
       " 'poliwag',\n",
       " 'poliwhirl',\n",
       " 'poliwrath',\n",
       " 'ponyta',\n",
       " 'porygon',\n",
       " 'primeape',\n",
       " 'psychic',\n",
       " 'psyduck',\n",
       " 'raichu',\n",
       " 'rapidash',\n",
       " 'raticate',\n",
       " 'rattata',\n",
       " 'rhydon',\n",
       " 'rhyhorn',\n",
       " 'rock',\n",
       " 'sandshrew',\n",
       " 'sandslash',\n",
       " 'scyther',\n",
       " 'seadra',\n",
       " 'seaking',\n",
       " 'seel',\n",
       " 'shellder',\n",
       " 'slowbro',\n",
       " 'slowpoke',\n",
       " 'snorlax',\n",
       " 'spearow',\n",
       " 'squirtle',\n",
       " 'starmie',\n",
       " 'staryu',\n",
       " 'tangela',\n",
       " 'tauros',\n",
       " 'tentacool',\n",
       " 'tentacruel',\n",
       " 'the',\n",
       " 'type',\n",
       " 'vaporeon',\n",
       " 'venomoth',\n",
       " 'venonat',\n",
       " 'venusaur',\n",
       " 'victreebel',\n",
       " 'vileplume',\n",
       " 'voltorb',\n",
       " 'vulpix',\n",
       " 'wartortle',\n",
       " 'water',\n",
       " 'weedle',\n",
       " 'weepinbell',\n",
       " 'weezing',\n",
       " 'whats',\n",
       " 'wigglytuff',\n",
       " 'zapdos',\n",
       " 'zubat']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list = list(pp_df['question'].apply(lambda x: ' '.join(x)))\n",
    "answers_list = list(pp_df['answers'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "question_words = [word for sentence in question_list for word in sentence.split()]\n",
    "answers_words = [word for sentence in answers_list for word in sentence.split()]\n",
    "\n",
    "# # Remove duplicates and create the vocabulary list\n",
    "vocabulary_list = sorted(list(set(question_words + answers_words)))\n",
    "\n",
    "VOCAB_SIZE = len(vocabulary_list)+1\n",
    "print(VOCAB_SIZE)\n",
    "vocabulary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocabulary_list))\n",
    "idx_word = dict((i+1, c) for i,c in enumerate(vocabulary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_phrases(data, word_idx, question_maxlen):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for idx, row in data.iterrows():\n",
    "        x = [word_idx[w] for w in row['question']]\n",
    "        # y = np.zeros(len(word_idx) + 1)\n",
    "        # y = [word_idx[w] for w in row['answers']]\n",
    "        y = np.zeros(len(word_idx) + 1)\n",
    "        y[word_idx[row['answers'][0]]] = 1\n",
    "        # y[word_idx[row['answers'][0]]] = 1\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen=question_maxlen), np.array(Y))\n",
    "\n",
    "question_train, answers_train = vectorize_phrases(df_train,\n",
    "                                                word_idx,\n",
    "                                                VOCAB_SIZE)\n",
    "question_val, answers_val = vectorize_phrases(df_val,\n",
    "                                                word_idx,\n",
    "                                                VOCAB_SIZE)\n",
    "question_test, answers_test = vectorize_phrases(df_test,\n",
    "                                                word_idx,\n",
    "                                                VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 173), (105, 173))"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_train.shape, answers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: KerasTensor(type_spec=TensorSpec(shape=(None, 173), dtype=tf.float32, name='input_27'), name='input_27', description=\"created by layer 'input_27'\")\n",
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 173, 64), dtype=tf.float32, name=None), name='sequential_59/dropout_66/Identity:0', description=\"created by layer 'sequential_59'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 173, 173), dtype=tf.float32, name=None), name='sequential_60/dropout_67/Identity:0', description=\"created by layer 'sequential_60'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 173, 64), dtype=tf.float32, name=None), name='sequential_61/dropout_68/Identity:0', description=\"created by layer 'sequential_61'\")\n",
      "(None, 173, 173)\n",
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 173, 173), dtype=tf.float32, name=None), name='activation_24/Softmax:0', description=\"created by layer 'activation_24'\")\n",
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 173, 173), dtype=tf.float32, name=None), name='permute_14/transpose:0', description=\"created by layer 'permute_14'\")\n",
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 173, 237), dtype=tf.float32, name=None), name='concatenate_12/concat:0', description=\"created by layer 'concatenate_12'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 03:00:40.023119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-02 03:00:40.030435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-02 03:00:40.037714: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# placeholders\n",
    "MAX_SEQUENCE_LENGTH = VOCAB_SIZE\n",
    "input_sequence = Input((MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "print('Input sequence:', input_sequence)\n",
    "# print('Question:', question)\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size_q,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "\n",
    "\n",
    "# embed the input into a sequence of vectors of size MAX_SEQUENCE_LENGTH\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size_q,\n",
    "                              output_dim=MAX_SEQUENCE_LENGTH))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size_q,\n",
    "                               output_dim=64,\n",
    "                               input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, MAX_SEQUENCE_LENGTH, embedding_dim)\n",
    "\n",
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "print('Input encoded m', input_encoded_m)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "question_encoded = question_encoder(input_sequence)\n",
    "print('Question encoded', question_encoded)\n",
    "\n",
    "# compute a 'match' between the first input vector sequence\n",
    "# and the question vector sequence\n",
    "# shape: `(samples, story_maxlen, MAX_SEQUENCE_LENGTH)\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "print(match.shape)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, MAX_SEQUENCE_LENGTH)\n",
    "response = Permute((2, 1))(response)  # (samples, MAX_SEQUENCE_LENGTH, story_maxlen)\n",
    "print('Response shape', response)\n",
    "\n",
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "#answer = LSTM(lstm_size, return_sequences=True)(answer)  # Generate tensors of shape 32\n",
    "#answer = Dropout(0.3)(answer)\n",
    "LSTM_UNITS = 64\n",
    "answer = LSTM(LSTM_UNITS)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(VOCAB_SIZE)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the final model\n",
    "model = Model(input_sequence, answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.RandomSearch(\n",
    "#     hypermodel=Lstm(vocab_size_q, MAX_SEQUENCE_LENGTH, METRICS, None),\n",
    "#     objective=kt.Objective('accuracy', direction='max'),\n",
    "#     max_trials=1,\n",
    "#     executions_per_trial=1,\n",
    "#     # overwrite=True,\n",
    "#     directory=\"hyperparameters_search\",\n",
    "#     project_name=\"model\",\n",
    "#     seed=SEED_VAL\n",
    "# )\n",
    "\n",
    "# print(tuner.search_space_summary())\n",
    "\n",
    "# logdir = os.path.join(\"logs/model/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "# earlystopping_callback = keras.callbacks.EarlyStopping('val_loss', mode='min', verbose=1, patience=5)\n",
    "# # visualizer_callback = TrainingVisualizer()\n",
    "\n",
    "# callbacks_list = [earlystopping_callback, tensorboard_callback] #, visualizer_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 108, 121,   2],\n",
       "       [  0,   0,   0, ..., 108, 139,   2],\n",
       "       [  0,   0,   0, ..., 108, 117,   2],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 108,  48,   2],\n",
       "       [  0,   0,   0, ..., 108,  67,   2],\n",
       "       [  0,   0,   0, ..., 108, 105,   2]], dtype=int32)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165],\n",
       "       [165],\n",
       "       [106],\n",
       "       [165],\n",
       "       [ 57],\n",
       "       [ 46],\n",
       "       [ 60],\n",
       "       [ 51],\n",
       "       [ 12],\n",
       "       [135],\n",
       "       [127],\n",
       "       [120],\n",
       "       [106],\n",
       "       [106],\n",
       "       [120],\n",
       "       [165],\n",
       "       [165],\n",
       "       [106],\n",
       "       [ 12],\n",
       "       [ 46],\n",
       "       [120],\n",
       "       [ 38],\n",
       "       [ 60],\n",
       "       [ 51],\n",
       "       [120],\n",
       "       [ 38],\n",
       "       [ 57],\n",
       "       [ 12],\n",
       "       [ 57],\n",
       "       [106],\n",
       "       [165],\n",
       "       [ 45],\n",
       "       [165],\n",
       "       [165],\n",
       "       [ 12],\n",
       "       [165],\n",
       "       [165],\n",
       "       [ 12],\n",
       "       [106],\n",
       "       [120],\n",
       "       [127],\n",
       "       [ 45],\n",
       "       [120],\n",
       "       [ 46],\n",
       "       [165],\n",
       "       [106],\n",
       "       [120],\n",
       "       [ 45],\n",
       "       [165],\n",
       "       [ 46],\n",
       "       [ 46],\n",
       "       [106],\n",
       "       [ 60],\n",
       "       [106],\n",
       "       [135],\n",
       "       [165],\n",
       "       [ 12],\n",
       "       [ 60],\n",
       "       [165],\n",
       "       [135],\n",
       "       [ 46],\n",
       "       [ 42],\n",
       "       [ 46],\n",
       "       [ 57],\n",
       "       [127],\n",
       "       [127],\n",
       "       [ 57],\n",
       "       [ 45],\n",
       "       [ 38],\n",
       "       [120],\n",
       "       [135],\n",
       "       [165],\n",
       "       [127],\n",
       "       [165],\n",
       "       [ 42],\n",
       "       [165],\n",
       "       [ 38],\n",
       "       [127],\n",
       "       [165],\n",
       "       [ 68],\n",
       "       [106],\n",
       "       [ 29],\n",
       "       [ 57],\n",
       "       [165],\n",
       "       [ 46],\n",
       "       [135],\n",
       "       [120],\n",
       "       [ 12],\n",
       "       [ 57],\n",
       "       [135],\n",
       "       [ 46],\n",
       "       [165],\n",
       "       [ 38],\n",
       "       [106],\n",
       "       [ 12],\n",
       "       [165],\n",
       "       [ 57],\n",
       "       [135],\n",
       "       [ 57],\n",
       "       [165],\n",
       "       [165],\n",
       "       [ 12],\n",
       "       [ 51],\n",
       "       [127],\n",
       "       [ 46]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 173)]        0           []                               \n",
      "                                                                                                  \n",
      " sequential_59 (Sequential)     (None, None, 64)     7168        ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " sequential_61 (Sequential)     (None, 173, 64)      7168        ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " dot_16 (Dot)                   (None, 173, 173)     0           ['sequential_59[0][0]',          \n",
      "                                                                  'sequential_61[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 173, 173)     0           ['dot_16[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_60 (Sequential)     (None, None, 173)    19376       ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 173, 173)     0           ['activation_24[0][0]',          \n",
      "                                                                  'sequential_60[0][0]']          \n",
      "                                                                                                  \n",
      " permute_14 (Permute)           (None, 173, 173)     0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 173, 237)     0           ['permute_14[0][0]',             \n",
      "                                                                  'sequential_61[0][0]']          \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, 64)           77312       ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 64)           0           ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 173)          11245       ['dropout_69[0][0]']             \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 173)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 122,269\n",
      "Trainable params: 122,269\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "train_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 173)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 173)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 173)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 173)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 03:00:54.657573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [105,173]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-02 03:00:54.659620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype float and shape [105,173]\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-02 03:00:55.992385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-02 03:00:56.001435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-02 03:00:56.008596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-02 03:00:59.330374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-02 03:00:59.338004: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-02 03:00:59.343992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-02 03:01:02.798504: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: indices[0,167] = 169 is not in [0, 112)\n",
      "\t [[{{node model_12/sequential_59/embedding_57/embedding_lookup}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_12/sequential_59/embedding_57/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_38988/889928635.py\", line 1, in <module>\n      model.fit(question_train, answers_train, batch_size, train_epochs,\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_12/sequential_59/embedding_57/embedding_lookup'\nindices[0,167] = 169 is not in [0, 112)\n\t [[{{node model_12/sequential_59/embedding_57/embedding_lookup}}]] [Op:__inference_train_function_16751]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[406], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(question_train, answers_train, batch_size, train_epochs,\n\u001b[1;32m      2\u001b[0m           validation_data\u001b[39m=\u001b[39;49m(question_val, answers_val))\n",
      "File \u001b[0;32m~/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_12/sequential_59/embedding_57/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_38988/889928635.py\", line 1, in <module>\n      model.fit(question_train, answers_train, batch_size, train_epochs,\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/mayara/Documentos/unb/PAA/Q&A/Modelo-Paa/new_model/.venv/lib/python3.8/site-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_12/sequential_59/embedding_57/embedding_lookup'\nindices[0,167] = 169 is not in [0, 112)\n\t [[{{node model_12/sequential_59/embedding_57/embedding_lookup}}]] [Op:__inference_train_function_16751]"
     ]
    }
   ],
   "source": [
    "model.fit(question_train, answers_train, batch_size, train_epochs,\n",
    "          validation_data=(question_val, answers_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# tuner.search(question_train, answers_train,\n",
    "#              validation_data=(question_val, answers_val),\n",
    "#              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "Model.save(best_model, 'model')\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = Model.recover('model')\n",
    "\n",
    "EPOCHS = best_hps['epochs']\n",
    "BATCH_SIZE = best_hps['batch_size']\n",
    "LEARNING_RATE = best_hps['learning_rate']\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n",
    "\n",
    "hypermodel.compile(ptimizer='rmsprop',\n",
    "                    loss=LOSS, \n",
    "                    metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_val = hypermodel.evaluate(X_val_padded, Y_val_padded)\n",
    "\n",
    "y_probabilities_val = hypermodel.predict(X_val_padded)\n",
    "y_pred_val = np.argmax(y_probabilities_val, axis=1)\n",
    "y_val = np.argmax(Y_val_padded, axis=1)\n",
    "\n",
    "print('\\nValidation')\n",
    "print(classification_report(y_val, y_pred_val, zero_division=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result_test = hypermodel.evaluate(X_test_padded, Y_test_padded)\n",
    "\n",
    "y_probabilities_test = hypermodel.predict(X_test_padded)\n",
    "y_pred_test = np.argmax(y_probabilities_test, axis=1)\n",
    "y_test = np.argmax(Y_test_padded, axis=1)\n",
    "\n",
    "print('\\nTest')\n",
    "print(classification_report(y_test, y_pred_test, zero_division=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5742d98217a58e89dfcd3fa0aaeda25538af7f59f01db73a0aebe6b8570dd6d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
